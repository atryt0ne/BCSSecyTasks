{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Net From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fundamental Idea\n",
    "- In our body, neurons form the smallest unit of the brain\n",
    "- Each individual neuron is a pretty simple structure, it takes a few inputs (we represent them in a vector), modifies them (we represent these as multiplication by a weight and addition to a bias), and then sends the output forward\n",
    "- Such simple neurons arranged in very complex ways enable our brain to solve problems and identify patterns and what not\n",
    "- So the power of a neural network similarly will come from complex connections between simple units called neurons "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Unit\n",
    "- An individual neuron performs the following\n",
    "- $y = wx + b$\n",
    "- Here - \n",
    "1. x is the input\n",
    "2. w is the weight, the strength of the connection of this input to this neuron\n",
    "3. b is the bias\n",
    "4. y is the output\n",
    "\n",
    "## With Multiple Inputs\n",
    "- Each new input gets a new weight associated with it\n",
    "- $y = w_0x_0 + w_1x_1 + w_2x_2 ... + w_{n-1}x_{n-1} + b$\n",
    "\n",
    "## Now Multiple Neurons\n",
    "- One Neuron on its own is not that useful, so we make a lot of them, all acting on the same set of inputs - $x_0$ through $x_{n-1}$\n",
    "- Each set of such neurons is called a layer\n",
    "\n",
    "## Multiple Layers\n",
    "- Each layer is a rather simple transformation on a vector, but a stack of layers can handle a lot more complexity\n",
    "- However, if two layers are connected linearly, they are always going to be equivalent to one layer\n",
    "- To introduce non-linearity in this system, we connect layers with specialised functions called activation functions\n",
    "\n",
    "### Activation Function\n",
    "- These allow our layers to learn non-linear data\n",
    "- There are a few different types - tanh, sigmoid, ReLu, Leaky ReLu, softmax, etc.\n",
    "- But the basic purpose is the same, it can take a linear output of one layer and map it non-linearly before sending it as input to the next layer, thus introducing the non-linearity we want\n",
    "\n",
    "#### Dense Layers\n",
    "- A layer in which all the neurons take input from all the neurons of a previous layer\n",
    "\n",
    "#### Fully Connected Network \n",
    "- Network where all neurons of one layer connect to all neurons of the next layer\n",
    "\n",
    "## Make it capable of learning\n",
    "- While our network as it is now is capable of producing an output, it isn't capable of learning\n",
    "- This is called forward propagation - the flow of data from one layer to the next, till it produces an output at the end\n",
    "- But learning involves adjusting from mistakes, and we need a way to incorporate this\n",
    "\n",
    "## Mistakes - Loss Function\n",
    "- A Loss Function takes in the actual output the model was supposed to give, and the output the model predicted, and gives some value that can tell us how wrong the model was\n",
    "- Usually this is done by finding the mean square error.\n",
    "\n",
    "## Learning from a Mistake\n",
    "- Each weight and bias contributes to the final error value, and technically there must be an ideal value of weights and biases for which the model produces the correct output\n",
    "- Finding the correct value of a parameter using errors is accomplished by derivatives. We find the derivative of the error with respect to each parameter. Change the value of the parameter in steps to minimize the error.\n",
    "- Eventually the parameters will reach their ideal value, depending on how big the steps are.\n",
    "- This is called backward propagation.\n",
    "- The learning rate is the special parameter that decides the size of the steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic flow of a neural net is explained thusly - \n",
    "1. Feed input into the network\n",
    "2. Forward Propagation - Data flows from layer to layer till you get an output\n",
    "3. From the output, we can find a scalar error\n",
    "4. Backward Propagation - Differentiate the scalar error with respect to each parameter and adjust it\n",
    "5. Iterate again and again till error is minimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way I intend to approach this network is by defining simple template classes and then defining superclasses on them to make my final model\n",
    "\n",
    "## Basic Layer Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "    \n",
    "    def for_prop(self,input):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def back_prop(self,output_error,learning_rate):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connceted Layer Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Fully Connected Layer\n",
    "class FullCon_Layer(Layer):\n",
    "    def __init__(self,i_size,o_size):\n",
    "        self.weights = np.random.rand(i_size,o_size) - 0.5\n",
    "        self.bias = np.random.rand(1,o_size) - 0.5\n",
    "\n",
    "    def for_prop(self, i_data):\n",
    "        self.input = i_data\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "    \n",
    "    def back_prop(self, o_error, learning_rate):\n",
    "        i_error = np.dot(o_error, self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, o_error)\n",
    "\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * o_error\n",
    "        return i_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Layer Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Activation Layers\n",
    "class Activ_Layer(Layer):\n",
    "    def __init__(self, activ,activ_dash):\n",
    "        self.activation = activ\n",
    "        self.activation_dash = activ_dash\n",
    "    \n",
    "    def for_prop(self, i_data):\n",
    "        self.input = i_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "    \n",
    "    def back_prop(self, o_error, learning_rate):\n",
    "        return self.activation_dash(self.input) * o_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some specific activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some activation functions\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_dash(x):\n",
    "    return 1-np.tanh(x)**2\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_dash(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Functions\n",
    "def mean_sq_error(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true-y_pred,2))\n",
    "\n",
    "def deriv_error(y_true,y_pred):\n",
    "    return 2*(y_pred-y_true)/y_true.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Network Template\n",
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_dash = None\n",
    "    \n",
    "    def add_layer(self,layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def use_func(self,loss,loss_dash):\n",
    "        self.loss = loss\n",
    "        self.loss_dash = loss_dash\n",
    "    \n",
    "    def predict(self,i_data):\n",
    "        result = []\n",
    "        for i in i_data:\n",
    "            output = i\n",
    "            for layer in self.layers:\n",
    "                output = layer.for_prop(output)\n",
    "            result.append(output)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
    "        samples = len(x_train)\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.for_prop(output)\n",
    "\n",
    "                err += self.loss(y_train[j], output)\n",
    "\n",
    "                error = self.loss_dash(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.back_prop(error, learning_rate)\n",
    "\n",
    "            err /= samples\n",
    "            print(f'epoch {i+1}/{epochs}: error={err}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/40: error=0.09510017248606442\n",
      "epoch 2/40: error=0.07528109867367527\n",
      "epoch 3/40: error=0.06300385284568627\n",
      "epoch 4/40: error=0.05281841538954699\n",
      "epoch 5/40: error=0.045320136470309955\n",
      "epoch 6/40: error=0.03980616915025925\n",
      "epoch 7/40: error=0.035537480298379345\n",
      "epoch 8/40: error=0.03207767616291494\n",
      "epoch 9/40: error=0.029183010889167672\n",
      "epoch 10/40: error=0.026707043729420354\n",
      "epoch 11/40: error=0.024555029690879582\n",
      "epoch 12/40: error=0.022662380875471417\n",
      "epoch 13/40: error=0.02098443104635006\n",
      "epoch 14/40: error=0.019490502779520368\n",
      "epoch 15/40: error=0.018155128843872898\n",
      "epoch 16/40: error=0.016954627782864343\n",
      "epoch 17/40: error=0.015868691876561293\n",
      "epoch 18/40: error=0.014880867747338187\n",
      "epoch 19/40: error=0.013978143927683937\n",
      "epoch 20/40: error=0.013150199098016936\n",
      "epoch 21/40: error=0.012388525506674804\n",
      "epoch 22/40: error=0.01168572928449675\n",
      "epoch 23/40: error=0.011035190935115067\n",
      "epoch 24/40: error=0.010431072517388505\n",
      "epoch 25/40: error=0.009868544057884844\n",
      "epoch 26/40: error=0.009343993204935177\n",
      "epoch 27/40: error=0.00885487516599436\n",
      "epoch 28/40: error=0.008399134369609181\n",
      "epoch 29/40: error=0.007974646844087573\n",
      "epoch 30/40: error=0.007579035845740825\n",
      "epoch 31/40: error=0.007209767317015974\n",
      "epoch 32/40: error=0.006864359665918207\n",
      "epoch 33/40: error=0.006540631684486705\n",
      "epoch 34/40: error=0.006236875077319988\n",
      "epoch 35/40: error=0.005951828335080108\n",
      "epoch 36/40: error=0.00568452654015148\n",
      "epoch 37/40: error=0.0054342068895530705\n",
      "epoch 38/40: error=0.005200241299549481\n",
      "epoch 39/40: error=0.004981989601531007\n",
      "epoch 40/40: error=0.004778648429333927\n"
     ]
    }
   ],
   "source": [
    "# MNIST\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "# load data\n",
    "(x_train,y_train),(_x_test,_y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, 28*28)\n",
    "x_test = _x_test.reshape(_x_test.shape[0], 1, 28*28)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Convert 0-255 pixel intensity values to 0-1 range\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# The output is 0 - 9, however we will store it as an array of 10 boolean values instead\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(_y_test)\n",
    "\n",
    "Model = Network()\n",
    "Model.add_layer(FullCon_Layer(28*28,100))                 # Input\n",
    "Model.add_layer(Activ_Layer(tanh,tanh_dash))\n",
    "Model.add_layer(FullCon_Layer(100,50))\n",
    "Model.add_layer(Activ_Layer(sigmoid,sigmoid_dash))\n",
    "Model.add_layer(FullCon_Layer(50,10))\n",
    "Model.add_layer(Activ_Layer(sigmoid,sigmoid_dash))\n",
    "\n",
    "Model.use_func(mean_sq_error,deriv_error)\n",
    "Model.fit(x_train[0:1000],y_train[0:1000],epochs=40,learning_rate=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8    6    6    5    9    3    1    8    0    1    "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: \n",
      "8    2    6    3    9    3    1    8    0    1    "
     ]
    }
   ],
   "source": [
    "n = 10   # = no. of images to see predictions on\n",
    "\n",
    "index = np.random.choice(10000,size=n)\n",
    "\n",
    "for i,ind in enumerate(index):\n",
    "    plt.subplot(1,n,i+1)\n",
    "    plt.imshow(_x_test[ind])\n",
    "    plt.axis(\"off\")\n",
    "    print(np.argmax(y_test[ind]*255),end=\"    \")\n",
    "\n",
    "plt.show()\n",
    "print(\"Predicted value: \")\n",
    "for i,ind in enumerate(index):\n",
    "    predict = Model.predict(np.array([x_test[ind]]))[0]\n",
    "    digit = np.argmax(predict)\n",
    "    print(digit,end=\"    \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are reasonably correct, except in complex cases, which is to be expected as this is a very simple model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('rocket')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a48890fff9439756cc1be33bd857fb46c30bdda2d4e03894713857f536aa5155"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
